---
layout: post
title: Lessons Learned (Part 2: Performance Testing and Garbage Collection)
date: 2009-11-13
comments: false
---

<h1>{{ page.title }}</h1>
<div class='post'>
<div style="text-align: justify;">This is a continuation of <a target="_blank" href="http://patforna.blogspot.com/2009/10/lessons-learned-part-1-remembering.html">my previous blog post</a>. The goal is to sum up some lessons that I've learned during the last couple of months while I was involved in performance tuning a large-scale distributed web-app.<br /></div><br /><span style="font-weight: bold;font-size:120%;" >Golden Rules</span><br /><br /><div style="text-align: justify;">Although there are probably many more rules and good advice out there, these are the ones that I remember off the top of my head as being important:<br /></div><br /><span style="font-weight: bold; font-style: italic;">Change one thing at a time</span><br /><div style="text-align: justify;">I often found myself very tempted to violate this rule. The problem with breaking it, however, is easily illustrated with an example: Imagine that you make two changes, <span style="font-style: italic;">c1</span> and <span style="font-style: italic;">c2</span>, at the same time. If <span style="font-style: italic;">c1</span> results in a performance improvement of 20% and <span style="font-style: italic;">c2</span> in a performance penalty of 30% you'll get an overall performance deterioration of 10%. Consequently, you'll decide not to implement any of the changes, even though <span style="font-style: italic;">c1</span> on its own would have resulted in better performance.<br /></div><br /><span style="font-weight: bold; font-style: italic;">Look at the system as a whole and fix the slowest running part</span><br /><div style="text-align: justify;">Even if you can make some part of the system thousands of times faster, it will not affect you application performance if the part you changed was not your primary bottleneck. For example, it doesn't make sense to optimise application code if the bottleneck is the result of a slow running database query. I'd even go as far as saying that it is harmful to optimise parts of the systems, when it's not needed. Firstly, it's a waste of time that could be used for tasks that provide more value. Secondly, making performance optimisations often introduces additional complexity at the code level. If you can't justify this extra complexity with a significant performance boost, don't do it. Of course, I'm not advocating against common sense and sound software design principles. For example, I know that making lots of fine-grained RPC calls is a bad idea, so I'll avoid it in the first place.<br /></div><br /><span style="font-weight: bold; font-style: italic;">Don't optimise prematuerly, i.e. without measuring</span><br /><div style="text-align: justify;">This one probably goes hand in hand with the rule above. Don't optimise unless you can prove that it will have an effect on overall system performance. Again, this rule is not an excuse for not using sound software design principles.<br /></div><br /><span style="font-weight: bold;font-size:120%;" >Performance Testing Cycle</span><br /><br /><div style="text-align: justify;">Keeping the above rules in mind, we continuously iterated through the following cycle:<br /></div><ol style="text-align: justify;"><li>Measure performance</li><li>Identify single bottleneck (i.e. pick lowest hanging fruit)</li><li>Fix single bottleneck</li><li>Verify performance has improved</li></ol><div style="text-align: justify;">Once step 4 is complete, the cycle restarts. Sometimes, we would loop through this cycle several times a day. Other times, one loop would take us several days or even weeks. This process essentially continued until our release target was reached.<br /></div><br /><span style="font-weight: bold;font-size:120%;" >Measuring Performance</span><br /><br /><div style="text-align: justify;">We used <a target="_blank" href="http://jakarta.apache.org/jmeter/">JMeter</a> to generate load against the application under test. We set up the tests so that the generated load would increase over time and therefore put the application increasingly under more stress. While running the tests, we measured a number of parameters. The most important ones were throughput, average response time and CPU utilisation.<br /><br />Looking at charts similar to the ones shown below, we got a fairly good understanding of how much load the application under test could handle.<br /></div><a onblur="try {parent.deselectBloggerImageGracefully();} catch(e) {}" href="http://1.bp.blogspot.com/_MoEdKdmWnk0/Sv1uOpnLxpI/AAAAAAAAADk/qFckrFO2WI4/s1600-h/Picture+2.png"><img style="margin: 0px auto 10px; display: block; text-align: center; cursor: pointer; width: 400px; height: 129px;" src="http://1.bp.blogspot.com/_MoEdKdmWnk0/Sv1uOpnLxpI/AAAAAAAAADk/qFckrFO2WI4/s400/Picture+2.png" alt="" id="BLOGGER_PHOTO_ID_5403596325881890450" border="0" /></a><br /><div style="text-align: justify;">In the above charts, for example, you can see that, at some point, application throughput reaches a plateau while the average response time per transactions continuous to grow. At this point, the application reached some physical or logical limit that prevented it from doing more work. The challenge, of course, is to find out what those constraints are in order to increase throughput or reduce response times.<br /></div><br /><span style="font-weight: bold;font-size:120%;" >Identifying Bottlenecks</span><br /><br /><div style="text-align: justify;">Bottlenecks created by hardware constraints are normally quite easy to identify. Usually, the symptoms are maximum CPU utilisation, reaching network bandwidth limits, etc. The solution is often to change and restructure application code. Identifying bottlenecks not directly created by hardware constraints is more difficult. Likely causes are slow running external systems, resource starvation, suboptimal configuration settings, etc.<br /><br />In the last project, we eliminated the hypothesis that slow running external systems are constraining our system quite early by taking them out of the equation completely and using stub implementations instead. At the same time, this made our performance tests much more robust, reliable and faster.<br /></div><br /><span style="font-weight: bold;font-size:120%;" >Fixing Bottlenecks</span><br /><br /><div style="text-align: justify;">In the first few weeks of our performance tuning initiative, we made quite a lot of progress. There were a large number of easily identifiable bottlenecks which were relatively trivial to fix. These included simple programming errors, unnecessary database calls, unnecessary network calls, slow running SQL queries, no caching where data was easily cacheable, concurrency issues, etc.<br /><br />After some time, however, it started to get more difficult to identify bottlenecks. In particular, there has been one case that I think is worth writing about.<br /><br /><span style="font-weight: bold; font-style: italic;">Garbage Collection</span><br />We had already spent several weeks trying to identify a bottleneck, which was not obviously caused by hardware constraints. Here are the things we noticed:<br /></div><ul style="text-align: justify;"><li>Throughput reached a plateau at point <span style="font-style: italic;">t</span></li><li>Response time grew significantly at the same point <span style="font-style: italic;">t</span></li><li>Hardware was far from being exhausted. CPU utilisation, for example, was about 60% at point <span style="font-style: italic;">t</span></li><li>Although total CPU utilisation was around 60%, one (of eight) cores was maxing out occasionally</li></ul><div style="text-align: justify;">The last point was indicative that there was probably a CPU-intensive task executing in a single thread, hence single core. One such task that we could think of was garbage collection. We verified this using Perfmon and found that GC was indeed taking up a large amount of processing time (up to 30%).<br /><br />As a result, we did some reading on how .NET GC works. We've learned that, by default, the GC is optimised for standalone apps running on single-core machines (called Workstation GC). On multiprocessor machines, however, there is an additional GC mode available (called <a target="_blank" href="http://msdn.microsoft.com/en-us/library/ms229357.aspx">Server GC</a>). The difference between the two is basically that the latter creates a separate GC heap and GC thread for each processor and that collection occurs in parallel. Here's the change we made to our configuration:<br /><pre class="brush: xml; gutter: false;"><br />&lt;configuration&gt;<br />  &lt;runtime&gt;<br />    &lt;gcServer enabled="true" /&gt;<br />  &lt;/runtime&gt;<br />&lt;/configuration&gt;<br /></pre><br />After making the above configuration change, the throughput of our application increased by almost a factor 3! At the same time, we were again reaching 100% CPU utilisation and average GC time was down to 2-3%.<br /><br />Of course, this dramatic change meant that we were dealing with a completely new application profile. Consequently, we restarted our iterative cycle described above again from beginning in order to find the next bottleneck.<br /></div><br /><span style="font-weight: bold;font-size:120%;" >Conclusion</span><br /><br /><div style="text-align: justify;">The fundamental prerequisite for doing effective performance tuning is to have a set of repeatable and reliable performance tests. Ideally, these tests are easy to execute, finish in a reasonable amount of time and give you rapid feedback with regards to how the application is performing. Also, you'll need an isolated environment, which allows you to deploy new versions of the application easily and frequently. This gives you a good platform to experiment with changes. Measuring the difference between these changes with respect to the overall application performance then gives you the ability to make informed choices.</div></div>
<h2>Comments</h2>
<div class='comments'>
<div class='comment'>
<div class='author'>cc22</div>
<div class='content'>
This comment has been removed by the author.</div>
</div>
<div class='comment'>
<div class='author'>cc22</div>
<div class='content'>
This comment has been removed by the author.</div>
</div>
<div class='comment'>
<div class='author'>Gil Zilberfeld</div>
<div class='content'>
Hi Patric,<br /><br />We do a webcast on testing called “This week in testing” and this week, we talk about your post about performance testing.<br /><br />You’re welcome to watch and comment (http://learn.typemock.com/this-week-in-test/2009/11/18/episode-4-animals-that-talk-back.html) and if you like what you see, please tell the whole world.<br /><br />Thanks,<br /><br />Gil Zilberfeld<br />Typemock</div>
</div>
<div class='comment'>
<div class='author'>stej</div>
<div class='content'>
I was searching for &lt;gcServer ... /&gt; element, because I haven&#39;t seen it yet. Some sources claim it is true by default for asp.net applications. Are thery right?<br />One more question - somebody ran to issues with OutOfMemoryException when gcServer was enabled. Did you spot some problems like this?<br /><br />Concerning the measurement - how did you export the data from perfmon? Is there any other way instead of &#39;save image as..&#39;? I&#39;m asking because these questions led me to <a href="http://www.leporelo.eu/blog.aspx?id=performance-counters-series-export-to-excel" rel="nofollow">excel export</a></div>
</div>
<div class='comment'>
<div class='author'>Patric Fornasier</div>
<div class='content'>
@Andrew Profilers can be helpful tools to identify hotspots. Be aware, though, that your application profile will change as load on the system changes.<br /><br />Also, if you don&#39;t have a reliable way of measuring your application performance you run into danger of adding complexity and wasting time without actually improving performance.<br /><br />So, definitely fix the no-brainers but aim to have a minimal performance test suite as soon as possible. It will give you more confidence that your changes actually make a difference and keep you on the right path.</div>
</div>
<div class='comment'>
<div class='author'>Andrew</div>
<div class='content'>
Patrick<br /><br />Would you say there was value in running these profilers before performance testing began to &quot;optimise&quot; the code prior to performance testing?<br /><br />Andrew</div>
</div>
<div class='comment'>
<div class='author'>Patric Fornasier</div>
<div class='content'>
@Andrew Yes, we&#39;ve used Red Gate&#39;s Ants profiler. We&#39;ve also tried JetBrain dotTrace but I think most people preferred Ants.</div>
</div>
<div class='comment'>
<div class='author'>Andrew</div>
<div class='content'>
Hi<br /><br />You talk about identifying performance bottlenecks, did you consider using any profilers to identify CPU intensive code? <br /><br />Regards<br /><br />Andrew</div>
</div>
<div class='comment'>
<div class='author'>Patric Fornasier</div>
<div class='content'>
@stej We&#39;ve also used JMeter to measure the performance. We had JMeter write out the data to a file and then parsed it with a self-written little tool to extract and calculate the numbers we were interested in.<br /><br />In addition, we&#39;ve used Perfmon to measure other parameters such as CPU utilisation, memory usage, etc.</div>
</div>
<div class='comment'>
<div class='author'>Patric Fornasier</div>
<div class='content'>
@MauricioC yes, if you calculate the 30% on the 120% basis, then you&#39;re of course right. Either way, I&#39;m sure you got the point of the example =)</div>
</div>
<div class='comment'>
<div class='author'>stej</div>
<div class='content'>
You mentioned that you used JMeter to generate the load.<br />How did you <b>measure</b> the performance? <br /><br />I know that there is a VisualStudio for this task, but it&#39;s quite expensive. That&#39;s why I ended up with PowerShell script that was reading performance counters (I think the VisualStudio does the same).</div>
</div>
<div class='comment'>
<div class='author'>MauricioC</div>
<div class='content'>
&quot;If c1 results in a performance improvement of 20% and c2 in a performance penalty of 30% you&#39;ll get an overall performance deterioration of 10%.&quot;<br /><br />I think you mean 16%.</div>
</div>
</div>
